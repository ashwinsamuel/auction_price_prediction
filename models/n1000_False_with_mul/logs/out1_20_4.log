Getting data for 2025-03-03 00:00:00
Getting data for 2025-03-04 00:00:00
Getting data for 2025-03-05 00:00:00
Getting data for 2025-03-06 00:00:00
Getting data for 2025-03-07 00:00:00
Getting data for 2025-03-08 00:00:00
Getting data for 2025-03-09 00:00:00
Getting data for 2025-03-10 00:00:00
Getting data for 2025-03-11 00:00:00
Getting data for 2025-03-12 00:00:00
Getting data for 2025-03-13 00:00:00
Getting data for 2025-03-14 00:00:00
Getting data for 2025-03-15 00:00:00
Getting data for 2025-03-16 00:00:00
Getting data for 2025-03-17 00:00:00
Getting data for 2025-03-18 00:00:00
Getting data for 2025-03-19 00:00:00
Getting data for 2025-03-20 00:00:00
Getting data for 2025-03-21 00:00:00
Getting data for 2025-03-22 00:00:00
Getting data for 2025-03-23 00:00:00
Getting data for 2025-03-24 00:00:00
Getting data for 2025-03-25 00:00:00
Getting data for 2025-03-26 00:00:00
Getting data for 2025-03-27 00:00:00
Getting data for 2025-03-28 00:00:00
Getting data for 2025-03-29 00:00:00
Getting data for 2025-03-30 00:00:00
Getting data for 2025-03-31 00:00:00
1 - Basic features done
2 - Ratio features done
3 - Imbalance features done
4 - Rolling mean and std features done
5 - Diff features done
6 - Prev ref_prices features done
7 - Changes compared to prev imbalance features done
8 - MACD features done
252
Starting for w40_False with mul=1
40: 54m20sec done
40: 54m30sec done
40: 54m40sec done
40: 54m50sec done
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.336875 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 60530
[LightGBM] [Info] Number of data points in the train set: 2444400, number of used features: 247
[LightGBM] [Info] Start training from score 71.889999
Training until validation scores don't improve for 100 rounds
[10]	train's l1: 61.4718	test's l1: 61.4219
[20]	train's l1: 39.9246	test's l1: 39.9411
[30]	train's l1: 26.4957	test's l1: 26.563
[40]	train's l1: 18.8469	test's l1: 19.1389
[50]	train's l1: 11.3193	test's l1: 11.4192
[60]	train's l1: 7.43137	test's l1: 7.72561
[70]	train's l1: 6.61705	test's l1: 7.17826
[80]	train's l1: 6.33526	test's l1: 6.90196
[90]	train's l1: 5.12457	test's l1: 6.03715
[100]	train's l1: 4.38895	test's l1: 5.27172
[110]	train's l1: 4.13727	test's l1: 5.03047
[120]	train's l1: 4.12804	test's l1: 5.02446
[130]	train's l1: 4.11618	test's l1: 5.0248
[140]	train's l1: 4.11152	test's l1: 5.02133
[150]	train's l1: 4.02413	test's l1: 4.94306
[160]	train's l1: 3.91963	test's l1: 4.88516
[170]	train's l1: 3.86776	test's l1: 4.83822
[180]	train's l1: 3.67996	test's l1: 4.68963
[190]	train's l1: 3.61416	test's l1: 4.63337
[200]	train's l1: 3.46402	test's l1: 4.53625
[210]	train's l1: 3.43638	test's l1: 4.52341
[220]	train's l1: 3.38995	test's l1: 4.49387
[230]	train's l1: 3.35122	test's l1: 4.45504
[240]	train's l1: 3.33487	test's l1: 4.43796
[250]	train's l1: 3.33392	test's l1: 4.4375
[260]	train's l1: 3.32747	test's l1: 4.43293
[270]	train's l1: 3.29017	test's l1: 4.39167
[280]	train's l1: 3.28089	test's l1: 4.38531
[290]	train's l1: 3.27856	test's l1: 4.38381
[300]	train's l1: 3.25438	test's l1: 4.33319
[310]	train's l1: 3.2348	test's l1: 4.31995
[320]	train's l1: 3.21743	test's l1: 4.32417
[330]	train's l1: 3.16112	test's l1: 4.27905
[340]	train's l1: 3.12666	test's l1: 4.24278
[350]	train's l1: 3.12613	test's l1: 4.24191
[360]	train's l1: 3.09492	test's l1: 4.18926
[370]	train's l1: 3.09093	test's l1: 4.18837
[380]	train's l1: 3.03656	test's l1: 4.15839
[390]	train's l1: 3.01293	test's l1: 4.14086
[400]	train's l1: 3.01072	test's l1: 4.13989
[410]	train's l1: 3.00564	test's l1: 4.13487
[420]	train's l1: 3.00505	test's l1: 4.13535
[430]	train's l1: 3.00261	test's l1: 4.13427
[440]	train's l1: 2.93267	test's l1: 4.07178
[450]	train's l1: 2.9279	test's l1: 4.06318
[460]	train's l1: 2.92779	test's l1: 4.0632
[470]	train's l1: 2.91195	test's l1: 4.02885
[480]	train's l1: 2.91027	test's l1: 4.02689
[490]	train's l1: 2.90882	test's l1: 4.02589
[500]	train's l1: 2.90682	test's l1: 4.02647
[510]	train's l1: 2.90665	test's l1: 4.02639
[520]	train's l1: 2.89475	test's l1: 4.02559
[530]	train's l1: 2.89281	test's l1: 4.02341
[540]	train's l1: 2.87285	test's l1: 4.01074
[550]	train's l1: 2.85479	test's l1: 3.99272
[560]	train's l1: 2.85223	test's l1: 3.99133
[570]	train's l1: 2.84969	test's l1: 3.99026
[580]	train's l1: 2.84808	test's l1: 3.98981
[590]	train's l1: 2.84388	test's l1: 3.97955
[600]	train's l1: 2.74421	test's l1: 3.8759
[610]	train's l1: 2.73513	test's l1: 3.86836
[620]	train's l1: 2.72706	test's l1: 3.86289
[630]	train's l1: 2.71671	test's l1: 3.85035
[640]	train's l1: 2.71207	test's l1: 3.84635
[650]	train's l1: 2.70915	test's l1: 3.84523
[660]	train's l1: 2.687	test's l1: 3.8365
[670]	train's l1: 2.64502	test's l1: 3.80765
[680]	train's l1: 2.63939	test's l1: 3.8072
[690]	train's l1: 2.63885	test's l1: 3.80733
[700]	train's l1: 2.62655	test's l1: 3.79555
[710]	train's l1: 2.62484	test's l1: 3.79572
[720]	train's l1: 2.62443	test's l1: 3.7955
[730]	train's l1: 2.59861	test's l1: 3.76586
[740]	train's l1: 2.598	test's l1: 3.76552
[750]	train's l1: 2.59553	test's l1: 3.76422
[760]	train's l1: 2.58403	test's l1: 3.75681
[770]	train's l1: 2.53024	test's l1: 3.70465
[780]	train's l1: 2.51235	test's l1: 3.69119
[790]	train's l1: 2.49296	test's l1: 3.6785
[800]	train's l1: 2.40805	test's l1: 3.59666
[810]	train's l1: 2.40704	test's l1: 3.59603
[820]	train's l1: 2.40647	test's l1: 3.59578
[830]	train's l1: 2.40495	test's l1: 3.59694
[840]	train's l1: 2.40215	test's l1: 3.59381
[850]	train's l1: 2.38571	test's l1: 3.5798
[860]	train's l1: 2.38285	test's l1: 3.57816
[870]	train's l1: 2.38134	test's l1: 3.57711
[880]	train's l1: 2.38022	test's l1: 3.57623
[890]	train's l1: 2.37744	test's l1: 3.57358
[900]	train's l1: 2.34425	test's l1: 3.55945
[910]	train's l1: 2.34394	test's l1: 3.55946
[920]	train's l1: 2.33699	test's l1: 3.55304
[930]	train's l1: 2.33524	test's l1: 3.55475
[940]	train's l1: 2.33262	test's l1: 3.55326
[950]	train's l1: 2.332	test's l1: 3.55278
[960]	train's l1: 2.3313	test's l1: 3.55213
[970]	train's l1: 2.33116	test's l1: 3.55208
[980]	train's l1: 2.33065	test's l1: 3.55269
[990]	train's l1: 2.32625	test's l1: 3.54752
[1000]	train's l1: 2.32601	test's l1: 3.54763
Did not meet early stopping. Best iteration is:
[993]	train's l1: 2.32622	test's l1: 3.54751
