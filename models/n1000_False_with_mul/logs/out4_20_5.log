0
1
2
3
4
5
6
0
1
2
3
4
5
6
0
1
2
3
4
5
6
0
1
2
3
4
5
6
0
Starting for w20_False with mul=4
20: 54m40sec done
20: 54m50sec done
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.343273 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 60530
[LightGBM] [Info] Number of data points in the train set: 2612400, number of used features: 247
[LightGBM] [Info] Start training from score 71.889999
Training until validation scores don't improve for 100 rounds
[10]	train's l1: 61.4541	test's l1: 61.4
[20]	train's l1: 39.8923	test's l1: 39.9037
[30]	train's l1: 26.4861	test's l1: 26.5471
[40]	train's l1: 18.2336	test's l1: 18.5392
[50]	train's l1: 11.0624	test's l1: 11.292
[60]	train's l1: 7.82277	test's l1: 8.03448
[70]	train's l1: 6.3266	test's l1: 6.76727
[80]	train's l1: 5.17749	test's l1: 5.6783
[90]	train's l1: 4.45291	test's l1: 5.08775
[100]	train's l1: 3.89062	test's l1: 4.62539
[110]	train's l1: 3.82275	test's l1: 4.54024
[120]	train's l1: 3.57166	test's l1: 4.27578
[130]	train's l1: 3.35205	test's l1: 4.10516
[140]	train's l1: 3.29728	test's l1: 4.06355
[150]	train's l1: 3.2658	test's l1: 4.03471
[160]	train's l1: 3.20475	test's l1: 4.00856
[170]	train's l1: 3.17423	test's l1: 3.9805
[180]	train's l1: 3.1388	test's l1: 3.96682
[190]	train's l1: 3.09571	test's l1: 3.92257
[200]	train's l1: 2.99142	test's l1: 3.85242
[210]	train's l1: 2.83983	test's l1: 3.7458
[220]	train's l1: 2.77089	test's l1: 3.71666
[230]	train's l1: 2.76997	test's l1: 3.71635
[240]	train's l1: 2.75618	test's l1: 3.71344
[250]	train's l1: 2.75058	test's l1: 3.71121
[260]	train's l1: 2.74429	test's l1: 3.70605
[270]	train's l1: 2.74295	test's l1: 3.70506
[280]	train's l1: 2.71748	test's l1: 3.69499
[290]	train's l1: 2.71298	test's l1: 3.69182
[300]	train's l1: 2.7047	test's l1: 3.68384
[310]	train's l1: 2.70273	test's l1: 3.68221
[320]	train's l1: 2.69135	test's l1: 3.67632
[330]	train's l1: 2.68675	test's l1: 3.67336
[340]	train's l1: 2.68053	test's l1: 3.6698
[350]	train's l1: 2.67617	test's l1: 3.66475
[360]	train's l1: 2.66728	test's l1: 3.66023
[370]	train's l1: 2.65206	test's l1: 3.65519
[380]	train's l1: 2.64991	test's l1: 3.65383
[390]	train's l1: 2.64655	test's l1: 3.65162
[400]	train's l1: 2.63958	test's l1: 3.64591
[410]	train's l1: 2.63614	test's l1: 3.64488
[420]	train's l1: 2.614	test's l1: 3.63856
[430]	train's l1: 2.61387	test's l1: 3.63853
[440]	train's l1: 2.56201	test's l1: 3.61103
[450]	train's l1: 2.56179	test's l1: 3.61098
[460]	train's l1: 2.55994	test's l1: 3.61004
[470]	train's l1: 2.52022	test's l1: 3.59836
[480]	train's l1: 2.46703	test's l1: 3.51576
[490]	train's l1: 2.44987	test's l1: 3.50308
[500]	train's l1: 2.44544	test's l1: 3.50163
[510]	train's l1: 2.4287	test's l1: 3.49056
[520]	train's l1: 2.42731	test's l1: 3.48982
[530]	train's l1: 2.42655	test's l1: 3.48959
[540]	train's l1: 2.42388	test's l1: 3.48827
[550]	train's l1: 2.42138	test's l1: 3.48705
[560]	train's l1: 2.42015	test's l1: 3.48609
[570]	train's l1: 2.41564	test's l1: 3.48293
[580]	train's l1: 2.41467	test's l1: 3.48226
[590]	train's l1: 2.41395	test's l1: 3.48212
[600]	train's l1: 2.41286	test's l1: 3.48201
[610]	train's l1: 2.41279	test's l1: 3.48193
[620]	train's l1: 2.41212	test's l1: 3.4828
[630]	train's l1: 2.41161	test's l1: 3.48243
[640]	train's l1: 2.39861	test's l1: 3.44309
[650]	train's l1: 2.38331	test's l1: 3.40455
[660]	train's l1: 2.34542	test's l1: 3.34231
[670]	train's l1: 2.34409	test's l1: 3.34208
[680]	train's l1: 2.33686	test's l1: 3.32542
[690]	train's l1: 2.3212	test's l1: 3.31065
[700]	train's l1: 2.31366	test's l1: 3.29674
[710]	train's l1: 2.29717	test's l1: 3.28736
[720]	train's l1: 2.24322	test's l1: 3.25111
[730]	train's l1: 2.24266	test's l1: 3.25076
[740]	train's l1: 2.24168	test's l1: 3.2511
[750]	train's l1: 2.23984	test's l1: 3.25109
[760]	train's l1: 2.23953	test's l1: 3.25108
[770]	train's l1: 2.23262	test's l1: 3.25223
[780]	train's l1: 2.22947	test's l1: 3.25092
[790]	train's l1: 2.21628	test's l1: 3.2461
[800]	train's l1: 2.21612	test's l1: 3.24608
[810]	train's l1: 2.21599	test's l1: 3.24603
[820]	train's l1: 2.21433	test's l1: 3.24559
[830]	train's l1: 2.21257	test's l1: 3.24495
[840]	train's l1: 2.21156	test's l1: 3.24447
[850]	train's l1: 2.20969	test's l1: 3.24101
[860]	train's l1: 2.20706	test's l1: 3.24023
[870]	train's l1: 2.20638	test's l1: 3.23965
[880]	train's l1: 2.19008	test's l1: 3.22632
[890]	train's l1: 2.18591	test's l1: 3.22217
[900]	train's l1: 2.18467	test's l1: 3.22186
[910]	train's l1: 2.18453	test's l1: 3.22178
[920]	train's l1: 2.17755	test's l1: 3.21973
[930]	train's l1: 2.17431	test's l1: 3.21885
[940]	train's l1: 2.17193	test's l1: 3.21861
[950]	train's l1: 2.17081	test's l1: 3.2183
[960]	train's l1: 2.16945	test's l1: 3.21781
[970]	train's l1: 2.16808	test's l1: 3.21723
[980]	train's l1: 2.16748	test's l1: 3.21707
[990]	train's l1: 2.16272	test's l1: 3.21425
[1000]	train's l1: 2.15923	test's l1: 3.2128
Did not meet early stopping. Best iteration is:
[999]	train's l1: 2.15927	test's l1: 3.2128
